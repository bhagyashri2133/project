{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b470ec8d",
   "metadata": {},
   "source": [
    "### Project Story"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7378f96",
   "metadata": {},
   "source": [
    "Banks run into losses when a customer doesn't pay their loans on time. Because of this, every year, banks have losses in crores, and this also impacts the country's economic growth to a large extent. In this project we look at various attributes to predict if a person will be a loan defaulter or not.\n",
    "For this project we have build the model accourding to the data provided by the customer which contains attributes like \n",
    "Loan_ID, Gender, Married, Dependents, Education, Self_Employed, ApplicantIncome, CoapplicantIncome, LoanAmount, Loan_Amount_Term, Credit_History, Property_Area, Loan_Status.\n",
    "Data provided by the custumer consist of 614-rows and 13-columns including the target column.\n",
    "To work with python and Jupiter IDE we have to install libraries like 1) Numpy:- to work with arrays and numerical calculations 2)Pandas:- to analyze, clean, explore, and manipulate the data  3)seaborn:- to visualize the data , 4)matplotlib:- to plot graghs, 5)sklearn:- to implement machine learning models and statistical modelling 6)imblearn:- for oversampling the data 7)warning:- to ignore warnings  \n",
    "The dataset provided by customer had some prominant outliers so using z-score we identified the outliers but to avoid the data loss we cap those outliers with upper limit and lower limit. The dataset had missing values so we filled those missing values using statastics like mean, median, mode.Then we transformed the categorical data into numerical data using replace function mapping function and encoding techniques like OneHotEncoding , OrdinalEncoding, LableEncoding.\n",
    "As this was a Binary Classification type of problem where target column consist only two types outcomes we applied LogisticRegression where we applied StanderdScalar and transformed the data using PowerTransformer but the recall for 0 class in train and test datasets was very low so we took the ROC curv to find the right threashold to balance the values of recall and precision,  where we got good insights.\n",
    "Then we tried other models to find the optimum values of accuracy, recall, precision\n",
    "we trained the model using DicessionTreeClassifier where we hypertuned the parameters like criterion,max_depth,min_samples_split,min_samples_leaf and used GridSearchCV to find the best estimator\n",
    "we also apllied ensable techniques to build the model using RandomForestClassifier where we hypertuned the model with n_estimators,max_features,random_state to find the optimal values for accuracy, precision, recall\n",
    "Then we used the AdaBoost and GradientBoost where we hyper tuned the parameters n_estimators,random_state \n",
    "and lastly we used BaggingClassifier where we hypertuned the model using n_estimators,random_state.\n",
    "After evaluating every model we conclude that the LogisticRegression have the good accuracy, precision and recall values so we went with LogisticRegression model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7c6b6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "from sklearn.metrics import recall_score,precision_score,f1_score\n",
    "from sklearn.metrics import plot_confusion_matrix,roc_curve,precision_recall_curve\n",
    "\n",
    "#from imblearn.over_sampling import RandomOverSampler,ADASYN,SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score,recall_score,accuracy_score, f1_score, confusion_matrix,classification_report,r2_score,log_loss,auc\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e6c2aa",
   "metadata": {},
   "source": [
    "### Data Gathering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87130789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001002</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001003</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001005</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001006</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001008</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>LP002978</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>LP002979</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>LP002983</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>8072</td>\n",
       "      <td>240.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>LP002984</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>7583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>LP002990</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Semiurban</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>598 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Loan_ID  Gender Married  Dependents     Education Self_Employed  \\\n",
       "0    LP001002    Male      No         0.0      Graduate            No   \n",
       "1    LP001003    Male     Yes         1.0      Graduate            No   \n",
       "2    LP001005    Male     Yes         0.0      Graduate           Yes   \n",
       "3    LP001006    Male     Yes         0.0  Not Graduate            No   \n",
       "4    LP001008    Male      No         0.0      Graduate            No   \n",
       "..        ...     ...     ...         ...           ...           ...   \n",
       "593  LP002978  Female      No         0.0      Graduate            No   \n",
       "594  LP002979    Male     Yes         3.0      Graduate            No   \n",
       "595  LP002983    Male     Yes         1.0      Graduate            No   \n",
       "596  LP002984    Male     Yes         2.0      Graduate            No   \n",
       "597  LP002990  Female      No         0.0      Graduate           Yes   \n",
       "\n",
       "     ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0               5849                0.0         NaN             360.0   \n",
       "1               4583             1508.0       128.0             360.0   \n",
       "2               3000                0.0        66.0             360.0   \n",
       "3               2583             2358.0       120.0             360.0   \n",
       "4               6000                0.0       141.0             360.0   \n",
       "..               ...                ...         ...               ...   \n",
       "593             2900                0.0        71.0             360.0   \n",
       "594             4106                0.0        40.0             180.0   \n",
       "595             8072              240.0       253.0             360.0   \n",
       "596             7583                0.0       187.0             360.0   \n",
       "597             4583                0.0       133.0             360.0   \n",
       "\n",
       "     Credit_History Property_Area Loan_Status  \n",
       "0               1.0         Urban           Y  \n",
       "1               1.0         Rural           N  \n",
       "2               1.0         Urban           Y  \n",
       "3               1.0         Urban           Y  \n",
       "4               1.0         Urban           Y  \n",
       "..              ...           ...         ...  \n",
       "593             1.0         Rural           Y  \n",
       "594             1.0         Rural           Y  \n",
       "595             1.0         Urban           Y  \n",
       "596             1.0         Urban           Y  \n",
       "597             0.0     Semiurban           N  \n",
       "\n",
       "[598 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv(\"LoanApprovalPrediction.csv\")                  #------loading dataset\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030593bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape                                                    #----Number of columns and rows in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaa65d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()                                                                    #------Reading first 5 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea58fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()              #----Displaying all the columns in dataset with their respective datatype and non null value count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5fbbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()                          #----------Correlation between the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c89da6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()                             #----gives the static values for dadaframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8916e154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan_ID               0\n",
       "Gender                0\n",
       "Married               0\n",
       "Dependents           12\n",
       "Education             0\n",
       "Self_Employed         0\n",
       "ApplicantIncome       0\n",
       "CoapplicantIncome     0\n",
       "LoanAmount           21\n",
       "Loan_Amount_Term     14\n",
       "Credit_History       49\n",
       "Property_Area         0\n",
       "Loan_Status           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()                    #------checking for null values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aeeb833",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num = df.select_dtypes(exclude=object)           #--------checking for numerical columns\n",
    "df_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a1658c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num.shape                                      #---------number of rows and columns for numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8711d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_obj = df.select_dtypes(include=object)          #---------checking for categorical columns\n",
    "df_obj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd50614c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_obj.shape                                       #-----------number of rows and columns for categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7ee91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df[\"Loan_Status\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d761d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c12d4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()                          #----------Correlation between the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc6a627",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "df.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a55351",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df[\"ApplicantIncome\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53e8600",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df[\"CoapplicantIncome\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f16fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_limit = df[\"ApplicantIncome\"].mean() + 3*df[\"ApplicantIncome\"].std()\n",
    "lower_limit = df[\"ApplicantIncome\"].mean() - 3*df[\"ApplicantIncome\"].std()\n",
    "print('upper limit :-', upper_limit)\n",
    "print('lower limit :-', lower_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6850eb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_limit1 = df[\"CoapplicantIncome\"].mean() + 3*df[\"ApplicantIncome\"].std()\n",
    "lower_limit1 = df[\"CoapplicantIncome\"].mean() - 3*df[\"ApplicantIncome\"].std()\n",
    "print('upper limit :-', upper_limit1)\n",
    "print('lower limit :-', lower_limit1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b14b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_data = df.loc[(df[\"ApplicantIncome\"] > upper_limit) | (df[\"ApplicantIncome\"] < lower_limit)]\n",
    "outliers_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3034d0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_data1 = df.loc[(df[\"CoapplicantIncome\"] > upper_limit1) | (df[\"CoapplicantIncome\"] < lower_limit1)]\n",
    "outliers_data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e173ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"ApplicantIncome\"]>=upper_limit, 'ApplicantIncome']=upper_limit\n",
    "df.loc[df[\"ApplicantIncome\"]<=lower_limit, 'ApplicantIncome']=lower_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e504eeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df[\"ApplicantIncome\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa68bb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"CoapplicantIncome\"]>=upper_limit, 'CoapplicantIncome']=upper_limit1\n",
    "df.loc[df[\"CoapplicantIncome\"]<=lower_limit, 'CoapplicantIncome']=lower_limit1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036984cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df[\"CoapplicantIncome\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718c6cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c548d6",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69e0258",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()                           #----------number of unique values of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cec178e",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_cardinality_cols=[cname for cname in df.columns if df[cname].nunique()<5]  #--checking for unique values of each feature are less than 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9ec841",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_cardinality_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb6aa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_cardinality_cols=[cname for cname in df.columns if df[cname].nunique()>5]  #--checking for unique values of each feature are more than 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576368d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_cardinality_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784724c9",
   "metadata": {},
   "source": [
    "Here we can se that the low_cardinality_cols output has some feature which are having unique values less than five and high_cardinality_cols have 'Loan_ID' having unique values greater than 5 this insights it will help us for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13766824",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()                              #-------------------number of missing value in each feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e21e37c",
   "metadata": {},
   "source": [
    "Here we can see that there are missing values in 'Gender', 'Married', 'Dependents', 'Self_Employed','LoanAmount', 'Loan_Amount_Term', 'Credit_History' so we have to fill those missing values.\n",
    "\n",
    "so we have to fill these missing values using mean, mode and median."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c5f213",
   "metadata": {},
   "source": [
    "#### 1) Handling missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323d44fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dff855",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Gender\"].mode()                                   #-----------------extracting mode of categorical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f3e05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Gender\"].fillna(\"Male\" , inplace=True)            #--------------filling null values with extracted mode value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14204d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Married\"].mode()                                  #-----------------extracting mode of categorical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be12ac11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Married\"].fillna(\"Yes\" , inplace=True)           #--------------filling null values with extracted mode value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91af83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Self_Employed\"].mode()                           #-----------------extracting mode of categorical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe55cc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Self_Employed\"].fillna(\"No\" , inplace=True)      #--------------filling null values with extracted mode value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7bedfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Dependents\"].mode()                              #-----------------extracting mode of categorical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4426fd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Dependents\"].fillna(\"0\" , inplace=True)          #--------------filling null values with extracted mode value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c89c007",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"LoanAmount\"] = df[\"LoanAmount\"].fillna(df[\"LoanAmount\"].mean())      #--filling null values with mean value of loanAmount column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d99d287",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Loan_Amount_Term\"].value_counts()             #----count of unique values in Loan_Amount_Term with its datatype "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bcbfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Loan_Amount_Term\"].mode()                      #------extracting mode of categorical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116eb1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Loan_Amount_Term\"].fillna(360.0 , inplace=True)  #------filling null values with extracted mode value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb415bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Credit_History\"].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b25b546",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Credit_History\"].median()                     #------extracting mode of categorical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c712768",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Credit_History\"] = df[\"Credit_History\"].fillna(df[\"Credit_History\"].median()) #--------------filling null values with extracted mode value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd0c244",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55793ec",
   "metadata": {},
   "source": [
    "As we can see all the missing values have been filled.\n",
    "Now the next step is to convert the categorical values in numeric form."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15839a07",
   "metadata": {},
   "source": [
    "#### 2)Data Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c30837b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.select_dtypes(include=object)          #---------checking for categorical columns\n",
    "df2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e68dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Gender\"].value_counts().to_dict()                           #------count of unique values for Gender column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f37dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Gender\"].replace({\"Male\": 0, \"Female\": 1},inplace=True)    #-------replacing object data with numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16220437",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Gender\"].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff5cd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Married\"].value_counts().to_dict()                          #------count of unique values for Married column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be18d0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Married\"].replace({\"No\": 0, \"Yes\": 1},inplace=True)        #-------replacing object data with numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d10ff0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Married\"].value_counts().to_dict()                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf190e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Education\"].value_counts().to_dict()                       #------count of unique values for Education column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fe9714",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Education\"].replace({\"Graduate\": 0, \"Not Graduate\": 1},inplace=True) #-------replacing object data with numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e494f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Education\"].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaeb54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Self_Employed\"].value_counts().to_dict()                    #------count of unique values for Education column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96ac3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Self_Employed\"].replace({\"No\" : 0, \"Yes\" : 1}, inplace=True)         #-------replacing object data with numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236116c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Self_Employed\"].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913eb3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Dependents\"].value_counts().to_dict()                       #------count of unique values for Education column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25e55aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Dependents\"].replace({\"0\" : 0, \"1\" : 1, \"2\" : 2, \"3+\" : 3}, inplace=True)#--replacing object data with numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49329a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Dependents\"].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda916ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Property_Area\"].value_counts().to_dict()                   #------count of unique values for Education column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478f82aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Property_Area\"].replace({\"Semiurban\":2, \"Urban\":1, \"Rural\":0}, inplace=True)#-------replacing object data with numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c306bccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Property_Area\"].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ca3bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Loan_Status\"].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4309c0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Loan_Status\"].replace({\"Y\" : 1, \"N\" : 0}, inplace=True)    #-------replacing object data with numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52ea90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Loan_Status\"].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b75cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6d6fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26eb3a3",
   "metadata": {},
   "source": [
    "As we can see that all the categorical data has been transformed into the numerical data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4b10b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_cardinality_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be638cae",
   "metadata": {},
   "source": [
    "As we can see that the Loan_ID column is a high cardinality column and we dont need this column for analysis as well so we need to drop that column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8ad8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df2=df.drop(\"Loan_ID\" , axis=1)\n",
    "new_df2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a96fbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = new_df2.drop(\"Loan_Status\",axis=1)\n",
    "y = new_df2[\"Loan_Status\"]\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25,random_state=40,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9aaaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_model = LogisticRegression()\n",
    "lg_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8008e8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(lg_model,x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2735614c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(lg_model,x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1891e4",
   "metadata": {},
   "source": [
    "##### Evaluation on Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb6677d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lg_model.predict(x_test)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion Matrix\\n\",cnf_matrix)\n",
    "\n",
    "accuarcy = accuracy_score(y_test,y_pred)\n",
    "print(\"Accuracy Score\\n\",accuarcy)\n",
    "\n",
    "clf_report = classification_report(y_test,y_pred)\n",
    "print(\"Classification report\\n\",clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56430ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lg_model.predict(x_train)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_train,y_pred)\n",
    "print(\"Confusion Matrix\\n\",cnf_matrix)\n",
    "\n",
    "accuarcy = accuracy_score(y_train,y_pred)\n",
    "print(\"Accuracy Score\\n\",accuarcy)\n",
    "\n",
    "clf_report = classification_report(y_train,y_pred)\n",
    "print(\"Classification report\\n\",clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb335b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = lg_model.predict_proba(x_train)\n",
    "y_pred_prob[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65de66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lg_model.predict(x_train)\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea21c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = lg_model.predict_proba(x_train)\n",
    "fpr,tpr,thresh = roc_curve(y_train,y_pred_prob[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3972e420",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr,tpr)\n",
    "plt.xlabel(\"False Positive Rate (FPR)\")\n",
    "plt.ylabel(\"True Positive Rate (TPR)\")\n",
    "plt.title(\"Receiver Operating Characteristic Curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4dec2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = lg_model.predict_proba(x_train)\n",
    "fpr,tpr,thresh = roc_curve(y_train,y_pred_prob[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f363810c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = lg_model.predict_proba(x_train)\n",
    "fpr,tpr,thresh = roc_curve(y_train,y_pred_prob[:,1])\n",
    "df1 = pd.DataFrame({\"Threshold\" :thresh,\n",
    "                   \"FPR\":fpr,\n",
    "                   \"TPR\":tpr,\n",
    "                   \"FNR\" :1-tpr})\n",
    "ax = df1.plot(x=\"Threshold\",y=[\"FPR\",\"FNR\"],figsize=(10,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc48c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = lg_model.predict_proba(x_train)\n",
    "fpr,tpr,thresh = roc_curve(y_train,y_pred_prob[:,1])\n",
    "index = np.where((thresh>0.73)&(thresh<0.75))\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad44f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "index1 = 80\n",
    "tpr[index1],fpr[index1],thresh[index1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4506d354",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_thresh = np.where(y_pred_prob[:,1]>=0.7267401231265038,1,0)\n",
    "confusion_matrix(y_train,tuned_thresh)\n",
    "plot_confusion_matrix(lg_model,y_train,tuned_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3339533f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=LogisticRegression()\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a7b79b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5296\\1529506077.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlr_prediction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy : '\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr_prediction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "lr_prediction=model.predict(x_test)\n",
    "print('Accuracy : ' , accuracy_score(lr_prediction,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097b09b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict([[0,0,0,0,0,0,0,156.412162,360.0,1.0,1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a03abd3",
   "metadata": {},
   "source": [
    "#### OverSampling using RamdomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54f6a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "ras = RandomOverSampler()\n",
    "x_train_re,y_train_re = ras.fit_resample(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a61ca99",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_re.shape ,y_train_re.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded2b7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_re.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3af96f",
   "metadata": {},
   "source": [
    "#### Scaling And Standerdizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ced4148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bac4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift the data by a positive constant\n",
    "shift_value = 0.00001\n",
    "x_train_shifted = x_train_re + shift_value\n",
    "x_test_shifted = x_test + shift_value\n",
    "\n",
    "# Instantiate the StandardScaler and fit_transform the shifted training data\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train_shifted)\n",
    "\n",
    "# Instantiate the PowerTransformer and fit_transform the scaled training data\n",
    "power_transformer = PowerTransformer(method='yeo-johnson')\n",
    "x_train_trans = power_transformer.fit_transform(x_train_scaled)\n",
    "\n",
    "# Transform the shifted test data using the same scaler and transformer\n",
    "x_test_scaled = scaler.transform(x_test_shifted)\n",
    "x_test_trans = power_transformer.transform(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72541db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = LogisticRegression()\n",
    "model_1.fit(x_train_trans,y_train_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9488d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_1 = model_1.predict(x_test_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8561a261",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_pred_1,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee46176",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_pred_1,y_test,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecd7d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8770e41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrc = LogisticRegression(penalty='l2')\n",
    "dtc = DecisionTreeClassifier(max_depth=5)\n",
    "knn = KNeighborsClassifier()\n",
    "rfc = RandomForestClassifier(n_estimators=36,max_features=11,random_state=18)\n",
    "gbc = GradientBoostingClassifier(n_estimators=71,random_state=12)\n",
    "adbc = AdaBoostClassifier(n_estimators=45,random_state=25)\n",
    "bgc = BaggingClassifier(n_estimators=77,random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6d424c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clasifier = {'LogisticRegression':lrc,\n",
    "             'DecisionTreeClassifier':dtc,\n",
    "             'KNeighborsClassifier':knn,\n",
    "             'RandomForestClassifier':rfc,\n",
    "             'GradientBoostingClassifier':gbc,\n",
    "             'AdaBoostClassifier':adbc,\n",
    "             'BaggingClassifier':bgc,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e6c54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(clf,x_train,x_test,y_train,y_test):\n",
    "    \n",
    "    clf.fit(x_train,y_train)\n",
    "    y_predict = clf.predict(x_test)\n",
    "    \n",
    "    accuracy_ = round(accuracy_score(y_test,y_predict),2)\n",
    "    precision_ = precision_score(y_test,y_predict,average='macro')\n",
    "    recall_score_ = recall_score(y_test,y_predict,average='macro')\n",
    "    \n",
    "    return accuracy_,precision_,recall_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba3b4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classifier(lrc,x_train_trans,x_test_trans,y_train_re,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad37609",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score_ = []\n",
    "precision_score_ = []\n",
    "recall_score__ = []\n",
    "\n",
    "for name ,clf in clasifier.items():\n",
    "    current_accuracy,current_precision,current_recall_score = train_classifier(clf,x_train_trans,x_test_trans,y_train_re,y_test)\n",
    "    \n",
    "    print('name :', name)\n",
    "    print('accuracy :', current_accuracy)\n",
    "    print('precision :' , current_precision)\n",
    "    print('recall_score',current_recall_score)\n",
    "    print('*'*50)\n",
    "    \n",
    "    accuracy_score_.append(current_accuracy)\n",
    "    precision_score_.append(current_precision)\n",
    "    recall_score__.append(current_recall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216c678a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.predict([[1,1,1,0,4500,0,0.0,146.412162,360.0,1.0,1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5792f3b",
   "metadata": {},
   "source": [
    "Here we can see that we can get good accuracy with Logistic Regression so we will go with LOgistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10242293",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.columns\n",
    "Gender = \"Male\"\n",
    "Married = \"Yes\"\n",
    "Dependents=\"2\"\n",
    "Education = \"Graduate\"\n",
    "Self_Employed = \"Yes\"\n",
    "ApplicantIncome=4699\n",
    "CoapplicantIncome=1200\n",
    "LoanAmount=66\n",
    "Loan_Amount_Term=360\n",
    "Credit_History=1\n",
    "Property_Area=\"Semiurban\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6df1610",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_data = {\"Gender\":{\"Male\": 0, \"Female\": 1},\n",
    "               \"Married\": {\"No\": 0, \"Yes\": 1},\n",
    "               \"Education\":{\"Graduate\": 0, \"Not Graduate\": 1},\n",
    "               \"Self_Employed\":{\"No\" : 0, \"Yes\" : 1},\n",
    "               \"Dependents\":{\"0\" : 0, \"1\" : 1, \"2\" : 2, \"3+\" : 3},\n",
    "               \"Property_Area\":{\"Semiurban\":2, \"Urban\":1, \"Rural\":0}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f12e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names=x.columns\n",
    "test_array = np.zeros(x.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee40af45",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_array[0]=project_data[\"Gender\"][\"Male\"]\n",
    "test_array[1]=project_data[\"Married\"][\"Yes\"]\n",
    "test_array[2]=project_data[\"Dependents\"][\"2\"]\n",
    "test_array[3]=project_data[\"Education\"][\"Graduate\"]\n",
    "test_array[4]=project_data[\"Self_Employed\"][\"Yes\"]\n",
    "test_array[5]=ApplicantIncome\n",
    "test_array[6]=CoapplicantIncome\n",
    "test_array[7]=LoanAmount\n",
    "test_array[8]=Loan_Amount_Term\n",
    "test_array[9]=Credit_History\n",
    "test_array[10]=project_data[\"Property_Area\"][\"Semiurban\"]\n",
    "test_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfb27ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_array[0] = self.json_data[\"Gender\"][self.Gender]\n",
    "test_array[1] = self.json_data[\"Married\"][self.Married]\n",
    "test_array[2] = self.json_data[\"Dependants\"][self.Dependants]\n",
    "test_array[3] = self.json_data[\"Education\"][self.Education]\n",
    "test_array[4] = self.json_data[\"Self_Employed\"][self.Self_Employed]\n",
    "test_array[5] = self.ApplicatIncome\n",
    "test_array[6] = self.CoapplicantIncome\n",
    "test_array[7] = self.LoanAmount\n",
    "test_array[8] = self.Loan_Aount_Term\n",
    "test_array[9] = self.Credit_History\n",
    "test_array[10] = self.json_data[\"Property_Area\"][self.Property_Area]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf79f35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.predict([test_array])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ed8313",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a586a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Logistic_model.pkl\",\"wb\") as file:\n",
    "    pickle.dump(model_1,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdca7c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"project_data.json\",\"w\") as file:\n",
    "    json.dump(project_data,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5e5552",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
